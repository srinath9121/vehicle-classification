{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1wJqDmtv3d45BArCwwPSeFEzzOuBQ29W-",
      "authorship_tag": "ABX9TyPhyOBei9WrnhiJ1LZmVpVi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinath9121/vehicle-classification/blob/main/transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5mQq_CYI5Ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "splits = {'train': 'data/train-00000-of-00001-be59bae1bcc8381f.parquet', 'validation': 'data/validation-00000-of-00001-58629e4f444d54b9.parquet', 'test': 'data/test-00000-of-00001-add65b65a0773a0f.parquet'}\n",
        "df = pd.read_parquet(\"hf://datasets/james-burton/data_scientist_salary_all_text/\" + splits[\"train\"])"
      ],
      "metadata": {
        "id": "qEw5hGyjJDuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "q3s9DG5nJKpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "bcBhX5_NJjzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['salary'].isnull()"
      ],
      "metadata": {
        "id": "z3lO9DIfZ4FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "lkqvTYnPYV9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "rcZuufgMYVhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds = load_dataset(\"DrBimmer/vehicle-classification\")"
      ],
      "metadata": {
        "id": "N1xngb3VZ7Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "at-7uvnzLaSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View available splits (like train/test)\n",
        "print(ds)\n",
        "\n",
        "# Look at one sample\n",
        "print(ds['train'][0])\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(ds['train'])\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "IBPjtM7hPrqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets transformers accelerate torchvision\n"
      ],
      "metadata": {
        "id": "y2-d8jY5Pt8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds)"
      ],
      "metadata": {
        "id": "sXyricIpWQUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"google/vit-base-patch16-224\"\n",
        "processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "\n",
        "def preprocess(examples):\n",
        "    images = [img.convert(\"RGB\") for img in examples[\"image\"]]\n",
        "    inputs = processor(images, return_tensors=\"pt\")\n",
        "    inputs[\"labels\"] = examples[\"type\"]  # or \"manufacturer\"\n",
        "    return inputs\n",
        "\n",
        "# Preprocess the dataset\n",
        "prepared_ds = ds.with_transform(preprocess)\n"
      ],
      "metadata": {
        "id": "KMZxvWq5WW5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(ds['train'][0]['image'])\n"
      ],
      "metadata": {
        "id": "Acnu6521WbHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ds['train'].features['label']\n",
        "print(labels)\n"
      ],
      "metadata": {
        "id": "d5XpUdCdYTJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels.int2str(0))\n",
        "print(labels.int2str(1))\n"
      ],
      "metadata": {
        "id": "Zn06BXtnZ5aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "example = ds['train'][0]\n",
        "plt.imshow(example['image'])\n",
        "plt.title(f\"Label: {ds['train'].features['label'].int2str(example['label'])}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Hquvx3sWaAi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pretrained Model"
      ],
      "metadata": {
        "id": "w1hzij3dgVlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Define the pretrained model checkpoint\n",
        "checkpoint = \"google/vit-base-patch16-224\"\n"
      ],
      "metadata": {
        "id": "lRSlG0PtjI3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
        "model = AutoModelForImageClassification.from_pretrained(checkpoint)\n"
      ],
      "metadata": {
        "id": "PJma7PJGjJ_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = ds[\"train\"].features[\"label\"].num_classes\n",
        "num_labels"
      ],
      "metadata": {
        "id": "lf5ypxDXjdrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor\n",
        "\n",
        "checkpoint = \"google/vit-base-patch16-224\"\n",
        "processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
        "\n",
        "def preprocess_batch(examples):\n",
        "    # examples is expected to be a dictionary of lists\n",
        "    images = [img.convert(\"RGB\") for img in examples[\"image\"]]\n",
        "    inputs = processor(images, return_tensors=\"pt\")\n",
        "    inputs[\"labels\"] = examples[\"label\"] # labels should be a list of integers\n",
        "    return inputs\n",
        "\n",
        "# Use map to preprocess the dataset upfront\n",
        "prepared_ds = ds.map(preprocess_batch, batched=True)\n",
        "\n",
        "# Select only the necessary columns\n",
        "prepared_ds = prepared_ds.select_columns(['pixel_values', 'labels'])"
      ],
      "metadata": {
        "id": "3FBWi1I8gaAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade transformers\n"
      ],
      "metadata": {
        "id": "GpBUCR4MqMJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "num_labels = ds[\"train\"].features[\"label\"].num_classes\n",
        "id2label = {i: ds[\"train\"].features[\"label\"].int2str(i) for i in range(num_labels)}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "     ignore_mismatched_sizes=True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "Kp0Bcs3SlBYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3ff62c9"
      },
      "source": [
        "!pip install -q evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return accuracy.compute(predictions=preds, references=p.label_ids)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vehicle-vit\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    push_to_hub=False\n",
        ")\n",
        "accuracy"
      ],
      "metadata": {
        "id": "JKYp_wsxlEn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy)"
      ],
      "metadata": {
        "id": "g5J07-RLs61e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=prepared_ds[\"train\"],\n",
        "    eval_dataset=prepared_ds[\"validation\"],\n",
        "    tokenizer=processor,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "5OMEngv_txK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate()\n",
        "print(\"Validation Accuracy:\", metrics[\"eval_accuracy\"])\n"
      ],
      "metadata": {
        "id": "GhDKZNbjt1yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, random\n",
        "\n",
        "sample = random.choice(ds[\"validation\"])\n",
        "inputs = processor(sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    pred_id = outputs.logits.argmax(-1).item()\n",
        "\n",
        "pred_label = id2label[pred_id]\n",
        "\n",
        "plt.imshow(sample[\"image\"])\n",
        "plt.title(f\"Predicted: {pred_label}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "f1z1uSpI8HUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./vehicle_model\")\n",
        "processor.save_pretrained(\"./vehicle_model\")\n"
      ],
      "metadata": {
        "id": "zYGHg45D8dJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds)"
      ],
      "metadata": {
        "id": "2KqyKvLO9CLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"/content/my_finetuned_model\"\n",
        "data_dir = \"/content/validation_data\"\n"
      ],
      "metadata": {
        "id": "eMwehS7XDitU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir"
      ],
      "metadata": {
        "id": "c5zVFr5qN_KX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# ðŸ”¹ STEP 1: Imports\n",
        "# ================================\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "import os # Import os to check for directory existence\n",
        "\n",
        "# ================================\n",
        "# ðŸ”¹ STEP 2: Load model and processor\n",
        "# Replace 'your_checkpoint' with your model name or saved folder\n",
        "# ================================\n",
        "model_path = \"./vehicle_model\" # Use the path to your saved model\n",
        "\n",
        "# Check if the model path exists\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Error: Model directory not found at {model_path}. Please ensure the directory exists.\")\n",
        "else:\n",
        "    model = AutoModelForImageClassification.from_pretrained(model_path)\n",
        "    processor = AutoImageProcessor.from_pretrained(model_path)\n",
        "\n",
        "    # ================================\n",
        "    # ðŸ”¹ STEP 3: Load new validation images\n",
        "    # Make sure your folder structure is:\n",
        "    # validation_data/\n",
        "    # â”œâ”€â”€ sedan/\n",
        "    # â”œâ”€â”€ suv/\n",
        "    # â”œâ”€â”€ truck/\n",
        "    # ================================\n",
        "    data_dir = \"/content/validation_data\"  # <-- change path to your folder\n",
        "\n",
        "    # Check if the data directory exists\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Error: Data directory not found at {data_dir}. Please ensure the directory exists and contains subfolders with images.\")\n",
        "    else:\n",
        "        try:\n",
        "            val_ds = load_dataset(\"imagefolder\", data_dir=data_dir, split=\"train\")\n",
        "            print(val_ds)\n",
        "\n",
        "            # ================================\n",
        "            # ðŸ”¹ STEP 4: Preprocess function\n",
        "            # This preprocesses a batch of examples\n",
        "            # ================================\n",
        "            def preprocess_batch(examples):\n",
        "                # examples is expected to be a dictionary of lists\n",
        "                images = [img.convert(\"RGB\") for img in examples[\"image\"]]\n",
        "                inputs = processor(images, return_tensors=\"pt\")\n",
        "                inputs[\"labels\"] = examples[\"label\"]\n",
        "                return inputs\n",
        "\n",
        "            # Apply preprocessing as a transformation (efficient for large datasets)\n",
        "            # This applies the preprocessing when data is accessed\n",
        "            val_ds = val_ds.with_transform(preprocess_batch)\n",
        "\n",
        "            # ================================\n",
        "            # ðŸ”¹ STEP 5: Run Predictions\n",
        "            # ================================\n",
        "            model.eval()\n",
        "\n",
        "            pred_labels = []\n",
        "            true_labels = []\n",
        "\n",
        "            # Iterate through the dataset using a DataLoader for batching\n",
        "            from torch.utils.data import DataLoader\n",
        "\n",
        "            # The collate_fn will be implicitly handled by with_transform if it returns tensors\n",
        "            dataloader = DataLoader(val_ds, batch_size=16) # Adjust batch size as needed\n",
        "\n",
        "            print(\"Running predictions...\")\n",
        "            for batch in dataloader:\n",
        "                inputs = {k: v.to(model.device) for k, v in batch.items()}\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(**inputs)\n",
        "\n",
        "                logits = outputs.logits\n",
        "                batch_pred_ids = logits.argmax(-1).tolist()\n",
        "                pred_labels.extend(batch_pred_ids)\n",
        "                true_labels.extend(inputs[\"labels\"].tolist())\n",
        "\n",
        "\n",
        "            # ================================\n",
        "            # ðŸ”¹ STEP 6: Convert IDs to names\n",
        "            # ================================\n",
        "            # Ensure the model's id2label is used, which was loaded from the saved model\n",
        "            id2label = model.config.id2label\n",
        "            pred_names = [id2label[i] for i in pred_labels]\n",
        "            true_names = [id2label[i] for i in true_labels]\n",
        "\n",
        "            # ================================\n",
        "            # ðŸ”¹ STEP 7: Accuracy + Report\n",
        "            # ================================\n",
        "            accuracy = np.mean(np.array(pred_labels) == np.array(true_labels))\n",
        "            print(f\"âœ… Validation Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "            print(\"\\nClassification Report:\")\n",
        "            # Ensure that all labels present in true_names and pred_names are included in the report\n",
        "            # This can be an issue if a class is not present in the validation set\n",
        "            # Get all possible labels from the model's id2label\n",
        "            target_names = list(id2label.values())\n",
        "\n",
        "            print(classification_report(true_names, pred_names, target_names=target_names, zero_division=0))\n",
        "\n",
        "            # ================================\n",
        "            # ðŸ”¹ STEP 8: Visualize random predictions\n",
        "            # Visualize a few samples from the original dataset for plotting\n",
        "            # Need to reload or access original images for visualization\n",
        "            # For simplicity, let's just show the predicted and true labels\n",
        "            # To show images, you would need to access the original images, perhaps by\n",
        "            # re-loading a few samples from the original imagefolder dataset or\n",
        "            # storing the original images/paths during loading.\n",
        "\n",
        "            print(\"\\nExample Predictions (True | Predicted):\")\n",
        "            # Select a few random indices to display\n",
        "            random_indices = random.sample(range(len(true_names)), min(5, len(true_names)))\n",
        "\n",
        "            for i in random_indices:\n",
        "                 print(f\"True: {true_names[i]} | Predicted: {pred_names[i]}\")\n",
        "\n",
        "            # Note: To visualize the actual images with labels, you would need to\n",
        "            # access the image data from the original dataset or store paths.\n",
        "            # The val_ds with transform applied doesn't directly hold image objects anymore.\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during dataset loading or prediction: {e}\")"
      ],
      "metadata": {
        "id": "Y9Mv06PqOBbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "Uynyf45sTk1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”¹ Unzip your uploaded file into /content/validation_data(1).zip\n",
        "!unzip -q validation_data.zip -d /content/validation_data(1).zip\n",
        "\n",
        "# ðŸ”¹ Check whether images and subfolders are extracted properly\n",
        "!ls /content/validation_data(1).zip\n"
      ],
      "metadata": {
        "id": "g-0fe3wOTzip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data_dir = \"/content/validation_data\"\n",
        "val_ds = load_dataset(\"imagefolder\", data_dir=data_dir, split=\"train\")\n",
        "\n",
        "print(val_ds)\n"
      ],
      "metadata": {
        "id": "Mf5S1CLeUJQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28VQ5atSUX5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}